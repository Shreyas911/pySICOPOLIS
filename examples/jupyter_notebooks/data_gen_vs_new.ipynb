{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa5a2e0-7d12-4f78-b9ef-4a7d88a734ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPC\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths and stuff\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# For surfvel data in tif files\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "sys.path.append('/home/shreyas/pySICOPOLIS/src')\n",
    "from pySICOPOLIS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3503fee7-d6d6-4964-af98-5fe11c1e21b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = '/home/shreyas/update_to_develop_sicopolis/sicopolis_spinups/sico_out/'\n",
    "dataPath = '/scratch2/shreyas/GrIS_paleo_data/'\n",
    "\n",
    "ds_surfvel_model_40km = xr.open_dataset(modelPath + 'grl40_bm5_paleo17a_nudged_CT4_BH0_m21ka_pkp/grl40_bm5_paleo17a_nudged_CT4_BH0_m21ka_pkp0007.nc')\n",
    "ds_surfvel_model_40km[\"vs\"] = ds_surfvel_model_40km['vh_s'].copy()\n",
    "ds_surfvel_model_40km[\"vx\"] = ds_surfvel_model_40km['vx_s_g'].copy()\n",
    "ds_surfvel_model_40km[\"vy\"] = ds_surfvel_model_40km['vy_s_g'].copy()\n",
    "ds_surfvel_model_40km[\"vs_uncert\"] = ds_surfvel_model_40km[\"vs\"].copy()*0.0 + 10.0\n",
    "ds_surfvel_model_40km[\"vx_uncert\"] = ds_surfvel_model_40km[\"vx\"].copy()*0.0 + 10.0\n",
    "ds_surfvel_model_40km[\"vy_uncert\"] = ds_surfvel_model_40km[\"vy\"].copy()*0.0 + 10.0\n",
    "ds_surfvel_model_40km.to_netcdf('/scratch2/shreyas/GrIS_paleo_data/fake_surfvel_data_40kms.nc', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8ec301-60a9-4b11-8a82-8c8d64d0ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xModel10 = np.arange(-72.,97.,1.0)*10\n",
    "yModel10 = np.arange(-345.,-56.,1.0)*10\n",
    "xModel16 = np.arange(-72.,97.,1.6)*10\n",
    "yModel16 = np.arange(-345.,-56.,1.6)*10\n",
    "xModel40 = np.arange(-72.,97.,4.0)*10\n",
    "yModel40 = np.arange(-345.,-56.,4.0)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34e7fca-69ed-4fcf-a19c-7276ea80c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_field_from_tif(file_path):\n",
    "\n",
    "    # Open the file\n",
    "    with rasterio.open(file_path) as dataset:\n",
    "\n",
    "        # # Print metadata information about the GeoTIFF file\n",
    "        # print(dataset.meta)\n",
    "        \n",
    "        # Read the data from the first band (if the image has multiple bands)\n",
    "        field = dataset.read(1)\n",
    "\n",
    "        # SSG: Invert y-axis to match Ralf's surfvel data convention\n",
    "        field = field[::-1]\n",
    "        \n",
    "        # # Accessing additional information\n",
    "        # print(f\"Width: {dataset.width}\")\n",
    "        # print(f\"Height: {dataset.height}\")\n",
    "        # print(f\"Number of Bands: {dataset.count}\")\n",
    "\n",
    "        return field\n",
    "\n",
    "vs_data = read_field_from_tif(\"/scratch2/shreyas/GrIS_paleo_data/greenland_vel_mosaic250_vs_v1.tif\")\n",
    "vx_data = read_field_from_tif(\"/scratch2/shreyas/GrIS_paleo_data/greenland_vel_mosaic250_vx_v1.tif\")\n",
    "vx_uncert_data = read_field_from_tif(\"/scratch2/shreyas/GrIS_paleo_data/greenland_vel_mosaic250_ex_v1.tif\")\n",
    "vy_data = read_field_from_tif(\"/scratch2/shreyas/GrIS_paleo_data/greenland_vel_mosaic250_vy_v1.tif\")\n",
    "vy_uncert_data = read_field_from_tif(\"/scratch2/shreyas/GrIS_paleo_data/greenland_vel_mosaic250_ey_v1.tif\")\n",
    "\n",
    "ds = xr.open_dataset(\"/scratch2/shreyas/GrIS_paleo_data/greenland_vel_mosaic250_vs_v1.nc\")\n",
    "xs = ds[\"x\"].data / 1000.0\n",
    "ys = ds[\"y\"].data / 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b804557-5381-4d8c-8e2c-eb3b49b215c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frac_area(x, y, xx, yy):\n",
    "    \"\"\"\n",
    "    Compute the fraction of the area of the small rectangle (xx, yy)\n",
    "    within the large rectangle (x, y).\n",
    "\n",
    "    Parameters:\n",
    "        x, y:   Length-2 arrays for the large rectangle [x1, x2], [y1, y2]\n",
    "        xx, yy: Length-2 arrays for the small rectangle\n",
    "\n",
    "    Returns:\n",
    "        Fraction of area of (xx, yy) within (x, y)\n",
    "    \"\"\"\n",
    "    x = sorted(x)\n",
    "    y = sorted(y)\n",
    "    xx = sorted(xx)\n",
    "    yy = sorted(yy)\n",
    "\n",
    "    dx_inv = 1.0 / (x[1] - x[0])\n",
    "    dy_inv = 1.0 / (y[1] - y[0])\n",
    "\n",
    "    xxm = [(xx[0] - x[0]) * dx_inv, (xx[1] - x[0]) * dx_inv]\n",
    "    yym = [(yy[0] - y[0]) * dy_inv, (yy[1] - y[0]) * dy_inv]\n",
    "\n",
    "    if (xxm[1] - xxm[0] > 1) or (yym[1] - yym[0] > 1):\n",
    "        raise ValueError(\"Small rectangle larger than large rectangle!\")\n",
    "\n",
    "    # Case 1: Fully inside\n",
    "    if 0 <= xxm[0] and xxm[1] <= 1 and 0 <= yym[0] and yym[1] <= 1:\n",
    "        return 1.0\n",
    "\n",
    "    # Partial overlaps along one edge\n",
    "    if 0 <= xxm[0] and xxm[1] <= 1:\n",
    "        if yym[0] < 0 < yym[1]:\n",
    "            return yym[1] / (yym[1] - yym[0])\n",
    "        elif yym[0] < 1 < yym[1]:\n",
    "            return (1 - yym[0]) / (yym[1] - yym[0])\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    if 0 <= yym[0] and yym[1] <= 1:\n",
    "        if xxm[0] < 0 < xxm[1]:\n",
    "            return xxm[1] / (xxm[1] - xxm[0])\n",
    "        elif xxm[0] < 1 < xxm[1]:\n",
    "            return (1 - xxm[0]) / (xxm[1] - xxm[0])\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    # Partial overlaps at corners\n",
    "    denom = (xxm[1] - xxm[0]) * (yym[1] - yym[0])\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "\n",
    "    if xxm[0] < 0 < xxm[1] and yym[0] < 0 < yym[1]:\n",
    "        return xxm[1] * yym[1] / denom\n",
    "    if xxm[0] < 1 < xxm[1] and yym[0] < 0 < yym[1]:\n",
    "        return (1 - xxm[0]) * yym[1] / denom\n",
    "    if xxm[0] < 0 < xxm[1] and yym[0] < 1 < yym[1]:\n",
    "        return xxm[1] * (1 - yym[0]) / denom\n",
    "    if xxm[0] < 1 < xxm[1] and yym[0] < 1 < yym[1]:\n",
    "        return (1 - xxm[0]) * (1 - yym[0]) / denom\n",
    "\n",
    "    return 0.0\n",
    "\n",
    "def downsample_field(xs, ys, field_data, x_sico, y_sico, dx_ms, dx):\n",
    "    \"\"\"\n",
    "    Downsample a 2D field using area-weighted averaging from fine to coarse grid.\n",
    "\n",
    "    Parameters:\n",
    "        xs, ys         - 1D fine grid coordinates (x_ms, y_ms)\n",
    "        field_data     - 2D array on fine grid, shape (len(ys), len(xs))\n",
    "        x_sico, y_sico - 1D coarse grid coordinates\n",
    "        dx_ms          - fine grid spacing\n",
    "        dx             - coarse grid spacing\n",
    "\n",
    "    Returns:\n",
    "        field_interp   - 2D array on coarse grid (len(y_sico), len(x_sico))\n",
    "    \"\"\"\n",
    "    field_interp = np.zeros((len(y_sico), len(x_sico)))\n",
    "    sum_weight = np.zeros_like(field_interp)\n",
    "    sum_weight_max = (dx / dx_ms) ** 2\n",
    "\n",
    "    for i, x in enumerate(x_sico):\n",
    "\n",
    "        for j, y in enumerate(y_sico):\n",
    "            if x < xs[0] or x > xs[-1] or y < ys[0] or y > ys[-1]:\n",
    "                continue\n",
    "\n",
    "            x1 = x - 0.5 * (dx + dx_ms)\n",
    "            x2 = x + 0.5 * (dx + dx_ms)\n",
    "            y1 = y - 0.5 * (dx + dx_ms)\n",
    "            y2 = y + 0.5 * (dx + dx_ms)\n",
    "\n",
    "            ii1 = int(np.floor((x1 - xs[0]) / dx_ms))\n",
    "            ii2 = int(np.ceil((x2 - xs[0]) / dx_ms))\n",
    "            jj1 = int(np.floor((y1 - ys[0]) / dx_ms))\n",
    "            jj2 = int(np.ceil((y2 - ys[0]) / dx_ms))\n",
    "\n",
    "            for ii in range(ii1, ii2):\n",
    "                for jj in range(jj1, jj2):\n",
    "                    if 0 <= ii < len(xs) and 0 <= jj < len(ys):\n",
    "                        val = field_data[jj, ii]\n",
    "                        if not np.isnan(val):\n",
    "                            weight = frac_area(\n",
    "                                [x - 0.5 * dx, x + 0.5 * dx],\n",
    "                                [y - 0.5 * dx, y + 0.5 * dx],\n",
    "                                [xs[ii] - 0.5 * dx_ms, xs[ii] + 0.5 * dx_ms],\n",
    "                                [ys[jj] - 0.5 * dx_ms, ys[jj] + 0.5 * dx_ms],\n",
    "                            )\n",
    "                            sum_weight[j, i] += weight\n",
    "                            field_interp[j, i] += weight * val\n",
    "\n",
    "            if sum_weight[j, i] > 0.5 * sum_weight_max:\n",
    "                field_interp[j, i] /= sum_weight[j, i]\n",
    "            else:\n",
    "                field_interp[j, i] = 0.0\n",
    "\n",
    "    return field_interp\n",
    "\n",
    "vx_data[vx_data < -1.5e9] = np.nan\n",
    "vy_data[vy_data < -1.5e9] = np.nan\n",
    "vs_data[vs_data < -1.5e9] = np.nan\n",
    "vx_uncert_data[vx_uncert_data < -1.5e9] = np.nan\n",
    "vy_uncert_data[vy_uncert_data < -1.5e9] = np.nan\n",
    "\n",
    "vs_data_interp = downsample_field(xs=xs, ys=ys, field_data=vs_data, x_sico=xModel40, y_sico=yModel40, dx_ms=0.25, dx=40.0)\n",
    "vx_data_interp = downsample_field(xs=xs, ys=ys, field_data=vx_data, x_sico=xModel40, y_sico=yModel40, dx_ms=0.25, dx=40.0)\n",
    "vy_data_interp = downsample_field(xs=xs, ys=ys, field_data=vy_data, x_sico=xModel40, y_sico=yModel40, dx_ms=0.25, dx=40.0)\n",
    "vx_uncert_data_interp = downsample_field(xs=xs, ys=ys, field_data=vx_uncert_data, x_sico=xModel40, y_sico=yModel40, dx_ms=0.25, dx=40.0)\n",
    "vy_uncert_data_interp = downsample_field(xs=xs, ys=ys, field_data=vy_uncert_data, x_sico=xModel40, y_sico=yModel40, dx_ms=0.25, dx=40.0)\n",
    "\n",
    "vx_uncert_data_interp[vx_uncert_data_interp == 0.0] = -2.e9\n",
    "vy_uncert_data_interp[vy_uncert_data_interp == 0.0] = -2.e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6be064d-fd14-411a-b1bd-bc04be185521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2575514/1181234617.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  np.nansum(np.abs((vs_orig-vs_data_interp)/vs_orig))/np.sum(vs_orig > 0), np.nansum(np.abs((vs_orig-vs_data_interp_calc)/vs_orig))/np.sum(vs_orig > 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.119570653391888e-08, 0.158914788798674)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_surfvel_data_40km_orig = xr.open_dataset(dataPath + 'surfvel_data_40kms_orig.nc')\n",
    "vs_orig = ds_surfvel_data_40km_orig[\"vs\"].data\n",
    "vs_data_interp_calc = np.sqrt(vx_data_interp**2 + vy_data_interp**2)\n",
    "np.nansum(np.abs((vs_orig-vs_data_interp)/vs_orig))/np.sum(vs_orig > 0), np.nansum(np.abs((vs_orig-vs_data_interp_calc)/vs_orig))/np.sum(vs_orig > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86b5175e-2a34-4a1d-bb4e-99d9b8fbfc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_vs_data_orig = xr.DataArray(\n",
    "        data = vs_orig,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = yModel40,\n",
    "            x = xModel40,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vs in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "da_vs_data_interp = xr.DataArray(\n",
    "        data = vs_data_interp,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = yModel40,\n",
    "            x = xModel40,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vs in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "da_vx_data_interp = xr.DataArray(\n",
    "        data = vx_data_interp,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = yModel40,\n",
    "            x = xModel40,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vx in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "da_vy_data_interp = xr.DataArray(\n",
    "        data = vy_data_interp,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = yModel40,\n",
    "            x = xModel40,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vy in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "da_vx_uncert_data_interp = xr.DataArray(\n",
    "        data = vx_uncert_data_interp,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = yModel40,\n",
    "            x = xModel40,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vx_uncert in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "da_vy_uncert_data_interp = xr.DataArray(\n",
    "        data = vy_uncert_data_interp,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = yModel40,\n",
    "            x = xModel40,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vy_uncert in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "ds_surfvel_data_40km = ds_surfvel_data_40km_orig.copy()\n",
    "ds_surfvel_data_40km[\"vs_orig\"] = da_vs_data_orig\n",
    "ds_surfvel_data_40km[\"vs\"] = da_vs_data_interp\n",
    "ds_surfvel_data_40km[\"vx\"] = da_vx_data_interp\n",
    "ds_surfvel_data_40km[\"vy\"] = da_vy_data_interp\n",
    "\n",
    "ds_surfvel_data_40km[\"vx_uncert_unbounded\"] = da_vx_uncert_data_interp\n",
    "ds_surfvel_data_40km[\"vx_uncert\"] = ds_surfvel_data_40km[\"vx_uncert_unbounded\"].copy()\n",
    "ratio_x = np.abs(vx_data_interp/vx_uncert_data_interp)\n",
    "ds_surfvel_data_40km[\"vx_uncert\"].data[ratio_x > 20.0] = 0.05*np.abs(vx_data_interp[ratio_x > 20.0])\n",
    "\n",
    "ds_surfvel_data_40km[\"vy_uncert_unbounded\"] = da_vy_uncert_data_interp\n",
    "ds_surfvel_data_40km[\"vy_uncert\"] = ds_surfvel_data_40km[\"vy_uncert_unbounded\"].copy()\n",
    "ratio_y = np.abs(vy_data_interp/vy_uncert_data_interp)\n",
    "ds_surfvel_data_40km[\"vy_uncert\"].data[ratio_y > 20.0] = 0.05*np.abs(vy_data_interp[ratio_y > 20.0])\n",
    "\n",
    "!rm /scratch2/shreyas/GrIS_paleo_data/surfvel_data_40kms.nc\n",
    "ds_surfvel_data_40km.to_netcdf(dataPath + 'surfvel_data_40kms.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_LRP",
   "language": "python",
   "name": "py310_lrp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
