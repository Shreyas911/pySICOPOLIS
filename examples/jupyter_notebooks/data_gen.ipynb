{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa5a2e0-7d12-4f78-b9ef-4a7d88a734ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPC\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths and stuff\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# For surfvel data in tif files\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "sys.path.append('/home/shreyas/pySICOPOLIS/src')\n",
    "from pySICOPOLIS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3503fee7-d6d6-4964-af98-5fe11c1e21b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = '/home/shreyas/update_to_develop_sicopolis/sicopolis_spinups/sico_out/'\n",
    "\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp = xr.open_dataset(modelPath + 'grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp/grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp0006.nc')\n",
    "\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert_real'] = ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c'] / 10.0\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert_real'] = ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert_real'].where(ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert_real'] > 1.0, 1.0)\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert_real'].attrs['units'] = 'a'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert_real'].attrs['standard_name'] = 'land_ice_kc_layer_age_uncert'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert_real'].attrs['long_name'] = 'Age uncertainty in the upper (kc) ice layer'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert_real'].attrs['grid_mapping'] = 'mapping'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert'] = ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c'] / 10.0\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert'] = ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert'].where(ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert'] > 1.0, 1.0)\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert'].attrs['units'] = 'a'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert'].attrs['standard_name'] = 'land_ice_kc_layer_age_uncert'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert'].attrs['long_name'] = 'Age uncertainty in the upper (kc) ice layer'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['age_c_uncert'].attrs['grid_mapping'] = 'mapping'\n",
    "\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['H_uncert'] = ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['H'] / 10.0\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['H_uncert'] = ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['H_uncert'].where(ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['H_uncert'] > 1.0, 1.0)\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['H_uncert'].attrs['units'] = 'm'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['H_uncert'].attrs['standard_name'] = 'land_ice_thickness_uncert'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['H_uncert'].attrs['long_name'] = 'Ice thickness uncertainty'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['H_uncert'].attrs['grid_mapping'] = 'mapping'\n",
    "\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zs_uncert'] = ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zs']*0.0 + 5.0\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zs_uncert'] = ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zs_uncert'].where(ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zs_uncert'] > 1.0, 1.0)\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zs_uncert'].attrs['units'] = 'm'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zs_uncert'].attrs['standard_name'] = 'land_ice_surface_uncert'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zs_uncert'].attrs['long_name'] = 'Ice surface uncertainty'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zs_uncert'].attrs['grid_mapping'] = 'mapping'\n",
    "\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zl_uncert'] = ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['H_uncert'].copy()\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zl_uncert'] = ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zl_uncert'].where(ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zl_uncert'] > 1.0, 1.0)\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zl_uncert'].attrs['units'] = 'm'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zl_uncert'].attrs['standard_name'] = 'land_ice_bed_uncert'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zl_uncert'].attrs['long_name'] = 'Ice bed uncertainty'\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp['zl_uncert'].attrs['grid_mapping'] = 'mapping'\n",
    "\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp.to_netcdf('/scratch2/shreyas/GrIS_paleo_data/fake_age_data_40kms.nc', mode='w')\n",
    "ds_grl40_bm5_paleo17a_CT4_BH0_m11ka_pkp.to_netcdf('/scratch2/shreyas/GrIS_paleo_data/fake_bm5_data_40kms.nc', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e08bab57-f61e-4892-9630-10111d887513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/scratch2/shreyas/GrIS_paleo_data/bm5_data_40kms_gs_before_masked.nc': No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyas/pySICOPOLIS/src/pySICOPOLIS/utils/data/ageData.py:254: RuntimeWarning: invalid value encountered in divide\n",
      "  filtered /= weight\n"
     ]
    }
   ],
   "source": [
    "dataPath = '/scratch2/shreyas/GrIS_paleo_data/'\n",
    "\n",
    "ds_temp = xr.open_dataset(dataPath + 'RDBTS4_Greenland_1993_2017_02_basal_thermal_state.nc')\n",
    "ds_vel  = xr.open_dataset(dataPath + 'RDGBV4_Greenland_1993_2013_01_balance_velocity_9ka.nc')\n",
    "ds_bm5  = xr.open_dataset(dataPath + 'BedMachineGreenland-v5.nc')\n",
    "ds_age  = xr.open_dataset(dataPath + 'RRRAG4_Greenland_1993_2013_01_age_grid.nc')\n",
    "\n",
    "# Copied file from '/home/shreyas/update_to_develop_sicopolis/sicopolis_spinups/sico_out/' to scratch2\n",
    "ds_model = xr.open_dataset(\"/scratch2/shreyas/GrIS_paleo_data/grl40_bm5_paleo17a_CT4_BH0_13point5CS_spinup_0ka0011.nc\")\n",
    "ds_sico_in = xr.open_dataset(\"/home/shreyas/update_to_develop_sicopolis/sicopolis/sico_in/grl/grl_bm5_40_topo.nc\")\n",
    "\n",
    "# Convert metres to kms\n",
    "ds_bm5['x'] = ds_bm5['x']*0.001\n",
    "ds_bm5['y'] = ds_bm5['y']*0.001\n",
    "ds_temp['x'] = ds_temp['x']*0.001\n",
    "ds_temp['y'] = ds_temp['y']*0.001\n",
    "\n",
    "# ds_age_correct = ageData.correctAgeDataset(ds_age,\n",
    "#                             path = dataPath,\n",
    "#                             filename = 'RRRAG4_Greenland_1993_2013_01_age_grid_corrected.nc',\n",
    "#                             zetaLevels = 26,\n",
    "#                             unCorrupt = True)\n",
    "ds_age_correct = xr.open_dataset(dataPath + 'RRRAG4_Greenland_1993_2013_01_age_grid_corrected.nc')\n",
    "\n",
    "xModel10       = np.arange(-72.,97.,1.0)*10\n",
    "yModel10       = np.arange(-345.,-56.,1.0)*10\n",
    "xModel16       = np.arange(-72.,97.,1.6)*10\n",
    "yModel16       = np.arange(-345.,-56.,1.6)*10\n",
    "xModel40       = np.arange(-72.,97.,4.0)*10\n",
    "yModel40       = np.arange(-345.,-56.,4.0)*10\n",
    "\n",
    "!rm /scratch2/shreyas/GrIS_paleo_data/bm5_data_40kms.nc\n",
    "ds_bm5_40kms = ageData.interpToModelGrid2D(ds = ds_bm5,\n",
    "                                           xModel = xModel40,\n",
    "                                           yModel = yModel40,\n",
    "                                           hor_interp_method = \"linear\",\n",
    "                                           bool_gausian_smoothing_before = False,\n",
    "                                           sigma_gs = 12.5,\n",
    "                                           replace_nans_with = -999.0,\n",
    "                                           path = dataPath,\n",
    "                                           filename = 'bm5_data_40kms.nc')\n",
    "ds_bm5_40kms[\"H_uncert_const\"] = ds_bm5_40kms[\"H_uncert\"].copy()\n",
    "ds_bm5_40kms[\"H_uncert_const\"].data[:, :] = 50\n",
    "ds_bm5_40kms[\"zl_uncert_const\"] = ds_bm5_40kms[\"H_uncert_const\"].copy()\n",
    "ds_bm5_40kms.to_netcdf(\"/scratch2/shreyas/GrIS_paleo_data/bm5_data_40kms.nc\")\n",
    "\n",
    "!rm /scratch2/shreyas/GrIS_paleo_data/bm5_data_40kms_gs_before.nc\n",
    "ds_bm5_40kms_gs_before = ageData.interpToModelGrid2D(ds = ds_bm5,\n",
    "                                                     xModel = xModel40,\n",
    "                                                     yModel = yModel40,\n",
    "                                                     hor_interp_method = \"linear\",\n",
    "                                                     bool_gausian_smoothing_before = True,\n",
    "                                                     sigma_gs = 12.5,\n",
    "                                                     replace_nans_with = -999.0,\n",
    "                                                     path = dataPath,\n",
    "                                                     filename = 'bm5_data_40kms_gs_before.nc')\n",
    "ds_bm5_40kms_gs_before[\"H_uncert_const\"] = ds_bm5_40kms_gs_before[\"H_uncert\"].copy()\n",
    "ds_bm5_40kms_gs_before[\"H_uncert_const\"].data[:, :] = 50\n",
    "ds_bm5_40kms_gs_before[\"zl_uncert_const\"] = ds_bm5_40kms_gs_before[\"H_uncert_const\"].copy()\n",
    "ds_bm5_40kms_gs_before.to_netcdf(\"/scratch2/shreyas/GrIS_paleo_data/bm5_data_40kms_gs_before.nc\")\n",
    "\n",
    "# mask = 1 - (ds_model[\"zs\"].data == ds_model[\"zl\"].data) * (ds_model[\"zs\"].data < -1000)\n",
    "# mask = 1 - (ds_model[\"zs\"].data == ds_model[\"zs\"].data[0,0])\n",
    "mask = 1 - (ds_model[\"zs\"].data < -50.0)\n",
    "\n",
    "!rm /scratch2/shreyas/GrIS_paleo_data/bm5_data_40kms_masked.nc\n",
    "ds_bm5_40kms_masked = ageData.interpToModelGrid2D(ds = ds_bm5,\n",
    "                                                  xModel = xModel40,\n",
    "                                                  yModel = yModel40,\n",
    "                                                  hor_interp_method = \"linear\",\n",
    "                                                  bool_gausian_smoothing_before = False,\n",
    "                                                  sigma_gs = 12.5,\n",
    "                                                  replace_nans_with = -999.0,\n",
    "                                                  path = dataPath,\n",
    "                                                  filename = 'bm5_data_40kms_masked.nc')\n",
    "ds_bm5_40kms_masked[\"H_uncert_const\"] = ds_bm5_40kms[\"H_uncert\"].copy()\n",
    "ds_bm5_40kms_masked[\"H_uncert_const\"].data[:, :] = 50*mask + (1-mask)*1.e8\n",
    "ds_bm5_40kms_masked[\"zl_uncert_const\"] = ds_bm5_40kms[\"H_uncert_const\"].copy()\n",
    "\n",
    "ds_bm5_40kms_masked[\"H\"].data = ds_bm5_40kms_masked[\"H\"].data*mask + (1-mask)*ds_model[\"H\"].data\n",
    "ds_bm5_40kms_masked[\"H_manual\"].data = ds_bm5_40kms_masked[\"H_manual\"].data*mask + (1-mask)*ds_model[\"H\"].data\n",
    "ds_bm5_40kms_masked[\"H_uncert\"].data = ds_bm5_40kms_masked[\"H_uncert\"].data*mask + (1-mask)*1.e8\n",
    "ds_bm5_40kms_masked[\"H_uncert_manual\"].data = ds_bm5_40kms_masked[\"H_uncert_manual\"].data*mask + (1-mask)*1.e8\n",
    "\n",
    "ds_bm5_40kms_masked[\"zs\"].data = ds_bm5_40kms_masked[\"zs\"].data*mask + (1-mask)*ds_model[\"zs\"].data\n",
    "ds_bm5_40kms_masked[\"zs_manual\"].data = ds_bm5_40kms_masked[\"zs_manual\"].data*mask + (1-mask)*ds_model[\"zs\"].data\n",
    "ds_bm5_40kms_masked[\"zs_uncert\"].data = ds_bm5_40kms_masked[\"zs_uncert\"].data*mask + (1-mask)*1.e8\n",
    "ds_bm5_40kms_masked[\"zs_uncert_manual\"].data = ds_bm5_40kms_masked[\"zs_uncert_manual\"].data*mask + (1-mask)*1.e8\n",
    "\n",
    "ds_bm5_40kms_masked[\"zl\"].data = ds_bm5_40kms_masked[\"zl\"].data*mask + (1-mask)*ds_model[\"zl\"].data\n",
    "ds_bm5_40kms_masked[\"zl_manual\"].data = ds_bm5_40kms_masked[\"zl_manual\"].data*mask + (1-mask)*ds_model[\"zl\"].data\n",
    "ds_bm5_40kms_masked[\"zl_uncert\"].data = ds_bm5_40kms_masked[\"zl_uncert\"].data*mask + (1-mask)*1.e8\n",
    "ds_bm5_40kms_masked[\"zl_uncert_manual\"].data = ds_bm5_40kms_masked[\"zl_uncert_manual\"].data*mask + (1-mask)*1.e8\n",
    "\n",
    "ds_bm5_40kms_masked.to_netcdf(\"/scratch2/shreyas/GrIS_paleo_data/bm5_data_40kms_masked.nc\")\n",
    "\n",
    "!rm /scratch2/shreyas/GrIS_paleo_data/bm5_data_40kms_gs_before_masked.nc\n",
    "ds_bm5_40kms_gs_before_masked = ageData.interpToModelGrid2D(ds = ds_bm5,\n",
    "                                                            xModel = xModel40,\n",
    "                                                            yModel = yModel40,\n",
    "                                                            hor_interp_method = \"linear\",\n",
    "                                                            bool_gausian_smoothing_before = True,\n",
    "                                                            sigma_gs = 12.5,\n",
    "                                                            replace_nans_with = -999.0,\n",
    "                                                            path = dataPath,\n",
    "                                                            filename = 'bm5_data_40kms_gs_before_masked.nc')\n",
    "\n",
    "ds_bm5_40kms_gs_before_masked[\"H_uncert_const\"] = ds_bm5_40kms_gs_before[\"H_uncert\"].copy()\n",
    "ds_bm5_40kms_gs_before_masked[\"H_uncert_const\"].data[:, :] = 50*mask + (1-mask)*1.e8\n",
    "ds_bm5_40kms_gs_before_masked[\"zl_uncert_const\"] = ds_bm5_40kms_gs_before[\"H_uncert_const\"].copy()\n",
    "\n",
    "ds_bm5_40kms_gs_before_masked[\"H\"].data = ds_bm5_40kms_gs_before_masked[\"H\"].data*mask + (1-mask)*ds_model[\"H\"].data\n",
    "ds_bm5_40kms_gs_before_masked[\"H_manual\"].data = ds_bm5_40kms_gs_before_masked[\"H_manual\"].data*mask + (1-mask)*ds_model[\"H\"].data\n",
    "ds_bm5_40kms_gs_before_masked[\"H_uncert\"].data = ds_bm5_40kms_gs_before_masked[\"H_uncert\"].data*mask + (1-mask)*1.e8\n",
    "ds_bm5_40kms_gs_before_masked[\"H_uncert_manual\"].data = ds_bm5_40kms_gs_before_masked[\"H_uncert_manual\"].data*mask + (1-mask)*1.e8\n",
    "\n",
    "ds_bm5_40kms_gs_before_masked[\"zs\"].data = ds_bm5_40kms_gs_before_masked[\"zs\"].data*mask + (1-mask)*ds_model[\"zs\"].data\n",
    "ds_bm5_40kms_gs_before_masked[\"zs_manual\"].data = ds_bm5_40kms_gs_before_masked[\"zs_manual\"].data*mask + (1-mask)*ds_model[\"zs\"].data\n",
    "ds_bm5_40kms_gs_before_masked[\"zs_uncert\"].data = ds_bm5_40kms_gs_before_masked[\"zs_uncert\"].data*mask + (1-mask)*1.e8\n",
    "ds_bm5_40kms_gs_before_masked[\"zs_uncert_manual\"].data = ds_bm5_40kms_gs_before_masked[\"zs_uncert_manual\"].data*mask + (1-mask)*1.e8\n",
    "\n",
    "ds_bm5_40kms_gs_before_masked[\"zl\"].data = ds_bm5_40kms_gs_before_masked[\"zl\"].data*mask + (1-mask)*ds_model[\"zl\"].data\n",
    "ds_bm5_40kms_gs_before_masked[\"zl_manual\"].data = ds_bm5_40kms_gs_before_masked[\"zl_manual\"].data*mask + (1-mask)*ds_model[\"zl\"].data\n",
    "ds_bm5_40kms_gs_before_masked[\"zl_uncert\"].data = ds_bm5_40kms_gs_before_masked[\"zl_uncert\"].data*mask + (1-mask)*1.e8\n",
    "ds_bm5_40kms_gs_before_masked[\"zl_uncert_manual\"].data = ds_bm5_40kms_gs_before_masked[\"zl_uncert_manual\"].data*mask + (1-mask)*1.e8\n",
    "\n",
    "ds_bm5_40kms_gs_before_masked.to_netcdf(\"/scratch2/shreyas/GrIS_paleo_data/bm5_data_40kms_gs_before_masked.nc\")\n",
    "\n",
    "exp_sigma_level  = dataCleaner.exp_sigma_level(zeta = np.arange(0,1+1./80,1./80),\n",
    "                                               exponent = 2.0)\n",
    "\n",
    "!rm /scratch2/shreyas/GrIS_paleo_data/age_data_40kms.nc\n",
    "ds_age_40kms = ageData.interpToModelGrid(ds_age_correct = ds_age_correct,\n",
    "                                         xModel = xModel40,\n",
    "                                         yModel = yModel40,\n",
    "                                         sigma_levelModel = exp_sigma_level,\n",
    "                                         hor_interp_method = \"linear\",\n",
    "                                         ver_interp_method = \"linear\",\n",
    "                                         bool_gausian_smoothing_before = False,\n",
    "                                         sigma_gs = 1.25,\n",
    "                                         replace_nans_with = -999.0,\n",
    "                                         path = dataPath,\n",
    "                                         filename = 'age_data_40kms.nc',\n",
    "                                         sigma = 1.0, truncate = 4)\n",
    "ds_age_40kms[\"age_c_uncert_const\"] = ds_age_40kms[\"age_c_uncert\"].copy()\n",
    "ds_age_40kms[\"age_c_uncert_const\"] = 500.0\n",
    "ds_age_40kms.to_netcdf(\"/scratch2/shreyas/GrIS_paleo_data/age_data_40kms.nc\")\n",
    "\n",
    "!rm /scratch2/shreyas/GrIS_paleo_data/age_data_40kms_gs_before.nc\n",
    "ds_age_40kms_gs_before = ageData.interpToModelGrid(ds_age_correct = ds_age_correct,\n",
    "                                                   xModel = xModel40,\n",
    "                                                   yModel = yModel40,\n",
    "                                                   sigma_levelModel = exp_sigma_level,\n",
    "                                                   hor_interp_method = \"linear\",\n",
    "                                                   ver_interp_method = \"linear\",\n",
    "                                                   bool_gausian_smoothing_before = True,\n",
    "                                                   sigma_gs = 1.25,\n",
    "                                                   replace_nans_with = -999.0,\n",
    "                                                   path = dataPath,\n",
    "                                                   filename = 'age_data_40kms_gs_before.nc',\n",
    "                                                   sigma = 1.0, truncate = 4)\n",
    "ds_age_40kms_gs_before[\"age_c_uncert_const\"] = ds_age_40kms[\"age_c_uncert\"].copy()\n",
    "ds_age_40kms_gs_before[\"age_c_uncert_const\"] = 500.0\n",
    "ds_age_40kms_gs_before.to_netcdf(\"/scratch2/shreyas/GrIS_paleo_data/age_data_40kms_gs_before.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34e7fca-69ed-4fcf-a19c-7276ea80c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_field_from_tif(file_path):\n",
    "\n",
    "    # Open the file\n",
    "    with rasterio.open(file_path) as dataset:\n",
    "\n",
    "        # # Print metadata information about the GeoTIFF file\n",
    "        # print(dataset.meta)\n",
    "        \n",
    "        # Read the data from the first band (if the image has multiple bands)\n",
    "        field = dataset.read(1)\n",
    "\n",
    "        # SSG: Invert y-axis to match Ralf's surfvel data convention\n",
    "        field = field[::-1]\n",
    "        \n",
    "        # # Accessing additional information\n",
    "        # print(f\"Width: {dataset.width}\")\n",
    "        # print(f\"Height: {dataset.height}\")\n",
    "        # print(f\"Number of Bands: {dataset.count}\")\n",
    "\n",
    "        return field\n",
    "\n",
    "vx_data = read_field_from_tif(\"/scratch2/shreyas/GrIS_paleo_data/greenland_vel_mosaic250_vx_v1.tif\")\n",
    "vx_uncert_data = read_field_from_tif(\"/scratch2/shreyas/GrIS_paleo_data/greenland_vel_mosaic250_ex_v1.tif\")\n",
    "vy_data = read_field_from_tif(\"/scratch2/shreyas/GrIS_paleo_data/greenland_vel_mosaic250_vy_v1.tif\")\n",
    "vy_uncert_data = read_field_from_tif(\"/scratch2/shreyas/GrIS_paleo_data/greenland_vel_mosaic250_ey_v1.tif\")\n",
    "vs_data = np.sqrt(vx_data**2 + vy_data**2)\n",
    "\n",
    "# Open the GeoTIFF file\n",
    "file_path = \"/scratch2/shreyas/GrIS_paleo_data/greenland_vel_mosaic250_ex_v1.tif\"\n",
    "with rasterio.open(file_path) as dataset:\n",
    "    # Get the transform (affine transformation) that maps pixel coordinates to geographic coordinates\n",
    "    transform = dataset.transform\n",
    "    \n",
    "    # Get the dimensions of the raster (number of rows and columns)\n",
    "    width = dataset.width\n",
    "    height = dataset.height\n",
    "    \n",
    "    # Get the CRS (Coordinate Reference System)\n",
    "    crs = dataset.crs\n",
    "    # print(f\"Coordinate Reference System (CRS): {crs}\")\n",
    "    \n",
    "    # Convert row, column indices to geographic coordinates (x, y)\n",
    "    # Example: Getting the coordinates of the top-left pixel\n",
    "    row, col = 0, 0  # Row, Column of the top-left pixel\n",
    "    x, y = transform * (col, row)  # This gives the coordinates (x, y) of that pixel\n",
    "    # print(f\"Top-left pixel coordinates: ({x}, {y})\")\n",
    "\n",
    "    # Convert the coordinates for other pixels (if needed)\n",
    "    # Let's get coordinates for the center pixel\n",
    "    center_row, center_col = height // 2, width // 2\n",
    "    center_x, center_y = transform * (center_col, center_row)\n",
    "    # print(f\"Center pixel coordinates: ({center_x}, {center_y})\")\n",
    "    \n",
    "    # Alternatively, to get the coordinates for every pixel:\n",
    "    # Generate a grid of column and row indices\n",
    "    rows, cols = np.indices((height, width))\n",
    "    \n",
    "    # Convert to coordinates using the affine transformation and change units to metres\n",
    "    xs, ys = transform * (cols, rows)\n",
    "    xs = 1.e-3 * xs\n",
    "    ys = 1.e-3 * ys\n",
    "\n",
    "    xs = xs[0]\n",
    "    ys = np.array([y[0] for y in ys])\n",
    "    ys = ys[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ea37ef-c637-48f2-9153-44004af7b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_data[vs_data > 1.e9] = np.nan\n",
    "da_vs_data = xr.DataArray(\n",
    "        data = vs_data,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = ys,\n",
    "            x = xs,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vs in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "vx_data[vx_data < -1.e9] = np.nan\n",
    "da_vx_data = xr.DataArray(\n",
    "        data = vx_data,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = ys,\n",
    "            x = xs,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vx in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "vy_data[vy_data < -1.e9] = np.nan\n",
    "da_vy_data = xr.DataArray(\n",
    "        data = vy_data,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = ys,\n",
    "            x = xs,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vy in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "vx_uncert_data[vx_uncert_data < -1.e9] = np.nan\n",
    "da_vx_uncert_data = xr.DataArray(\n",
    "        data = vx_uncert_data,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = ys,\n",
    "            x = xs,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vx_uncert in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "\n",
    "vy_uncert_data[vy_uncert_data < -1.e9] = np.nan\n",
    "da_vy_uncert_data = xr.DataArray(\n",
    "        data = vy_uncert_data,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = ys,\n",
    "            x = xs,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vy_uncert in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "\n",
    "da_vs_data_interp = da_vs_data.interp(x = xModel40, \n",
    "                                      y = yModel40,\n",
    "                                      method = \"linear\")\n",
    "da_vx_data_interp = da_vx_data.interp(x = xModel40, \n",
    "                                      y = yModel40,\n",
    "                                      method = \"linear\")\n",
    "da_vy_data_interp = da_vy_data.interp(x = xModel40, \n",
    "                                      y = yModel40,\n",
    "                                      method = \"linear\")\n",
    "da_vx_uncert_data_interp = da_vx_uncert_data.interp(x = xModel40, \n",
    "                                                    y = yModel40,\n",
    "                                                    method = \"linear\")\n",
    "da_vy_uncert_data_interp = da_vy_uncert_data.interp(x = xModel40, \n",
    "                                                    y = yModel40,\n",
    "                                                    method = \"linear\")\n",
    "\n",
    "da_vs_data_interp_manual = da_vs_data_interp.copy()\n",
    "da_vx_data_interp_manual = da_vx_data_interp.copy()\n",
    "da_vy_data_interp_manual = da_vy_data_interp.copy()\n",
    "da_vx_uncert_data_interp_manual = da_vx_uncert_data_interp.copy()\n",
    "da_vy_uncert_data_interp_manual = da_vy_uncert_data_interp.copy()\n",
    "\n",
    "da_vs_data_interp = da_vs_data_interp.fillna(-1.e9)\n",
    "da_vx_data_interp = da_vx_data_interp.fillna(-1.e9)\n",
    "da_vy_data_interp = da_vy_data_interp.fillna(-1.e9)\n",
    "da_vx_uncert_data_interp = da_vx_uncert_data_interp.fillna(-1.e9)\n",
    "da_vy_uncert_data_interp = da_vy_uncert_data_interp.fillna(-1.e9)\n",
    "\n",
    "for j in range(len(yModel40)):\n",
    "    for i in range(len(xModel40)):\n",
    "\n",
    "        j_data, alpha_y = ageData.find_alpha(ys, yModel40[j])\n",
    "        i_data, alpha_x = ageData.find_alpha(xs, xModel40[i])\n",
    "\n",
    "        if alpha_x is not None and alpha_y is not None:\n",
    "            \n",
    "            da_vs_data_interp_manual[j, i] = alpha_y*alpha_x*vs_data[j_data+1, i_data+1]\\\n",
    "                                            + (1-alpha_y)*alpha_x*vs_data[j_data, i_data+1]\\\n",
    "                                            + alpha_y*(1-alpha_x)*vs_data[j_data+1, i_data]\\\n",
    "                                            + (1-alpha_y)*(1-alpha_x)*vs_data[j_data, i_data]\n",
    "            da_vx_data_interp_manual[j, i] = alpha_y*alpha_x*vx_data[j_data+1, i_data+1]\\\n",
    "                                            + (1-alpha_y)*alpha_x*vx_data[j_data, i_data+1]\\\n",
    "                                            + alpha_y*(1-alpha_x)*vx_data[j_data+1, i_data]\\\n",
    "                                            + (1-alpha_y)*(1-alpha_x)*vx_data[j_data, i_data]\n",
    "            da_vy_data_interp_manual[j, i] = alpha_y*alpha_x*vy_data[j_data+1, i_data+1]\\\n",
    "                                            + (1-alpha_y)*alpha_x*vy_data[j_data, i_data+1]\\\n",
    "                                            + alpha_y*(1-alpha_x)*vy_data[j_data+1, i_data]\\\n",
    "                                            + (1-alpha_y)*(1-alpha_x)*vy_data[j_data, i_data]\n",
    "\n",
    "            da_vx_uncert_data_interp_manual[j, i] = np.sqrt(alpha_y**2*alpha_x**2*vx_uncert_data[j_data+1, i_data+1]**2\\\n",
    "                                                  + (1-alpha_y)**2*alpha_x**2*vx_uncert_data[j_data, i_data+1]**2\\\n",
    "                                                  + alpha_y**2*(1-alpha_x)**2*vx_uncert_data[j_data+1, i_data]**2\\\n",
    "                                                  + (1-alpha_y)**2*(1-alpha_x)**2*vx_uncert_data[j_data, i_data]**2)\n",
    "            da_vy_uncert_data_interp_manual[j, i] = np.sqrt(alpha_y**2*alpha_x**2*vy_uncert_data[j_data+1, i_data+1]**2\\\n",
    "                                                  + (1-alpha_y)**2*alpha_x**2*vy_uncert_data[j_data, i_data+1]**2\\\n",
    "                                                  + alpha_y**2*(1-alpha_x)**2*vy_uncert_data[j_data+1, i_data]**2\\\n",
    "                                                  + (1-alpha_y)**2*(1-alpha_x)**2*vy_uncert_data[j_data, i_data]**2)\n",
    "\n",
    "da_vs_data_interp_manual = da_vs_data_interp_manual.fillna(-1.e9)\n",
    "da_vx_data_interp_manual = da_vx_data_interp_manual.fillna(-1.e9)\n",
    "da_vy_data_interp_manual = da_vy_data_interp_manual.fillna(-1.e9)\n",
    "da_vx_uncert_data_interp_manual = da_vx_uncert_data_interp_manual.fillna(-1.e9)\n",
    "da_vy_uncert_data_interp_manual = da_vy_uncert_data_interp_manual.fillna(-1.e9)\n",
    "\n",
    "modelPath = '/home/shreyas/update_to_develop_sicopolis/sicopolis_spinups/sico_out/'\n",
    "dataPath = '/scratch2/shreyas/GrIS_paleo_data/'\n",
    "\n",
    "ds_surfvel_data_40km = xr.open_dataset(dataPath + 'surfvel_data_40kms.nc')\n",
    "ds_surfvel_data_40km_orig = xr.open_dataset(dataPath + 'surfvel_data_40kms_orig.nc')\n",
    "\n",
    "ds_surfvel_data_40km[\"vs_orig\"] = ds_surfvel_data_40km_orig[\"vs\"].copy()\n",
    "ds_surfvel_data_40km[\"vs\"] = da_vs_data_interp\n",
    "ds_surfvel_data_40km[\"vx\"] = da_vx_data_interp\n",
    "ds_surfvel_data_40km[\"vy\"] = da_vy_data_interp\n",
    "ds_surfvel_data_40km[\"vx_uncert\"] = da_vx_uncert_data_interp\n",
    "ds_surfvel_data_40km[\"vy_uncert\"] = da_vy_uncert_data_interp\n",
    "ds_surfvel_data_40km[\"vs_manual\"] = da_vs_data_interp_manual\n",
    "ds_surfvel_data_40km[\"vx_manual\"] = da_vx_data_interp_manual\n",
    "ds_surfvel_data_40km[\"vy_manual\"] = da_vy_data_interp_manual\n",
    "ds_surfvel_data_40km[\"vx_uncert_manual\"] = da_vx_uncert_data_interp_manual\n",
    "ds_surfvel_data_40km[\"vy_uncert_manual\"] = da_vy_uncert_data_interp_manual\n",
    "!rm /scratch2/shreyas/GrIS_paleo_data/surfvel_data_40kms.nc\n",
    "ds_surfvel_data_40km.to_netcdf(dataPath + 'surfvel_data_40kms.nc')\n",
    "\n",
    "ds_surfvel_model_40km = xr.open_dataset(modelPath + 'grl40_bm5_paleo17a_nudged_CT4_BH0_m21ka_pkp/grl40_bm5_paleo17a_nudged_CT4_BH0_m21ka_pkp0007.nc')\n",
    "ds_surfvel_model_40km[\"vs\"] = ds_surfvel_model_40km['vh_s'].copy()\n",
    "ds_surfvel_model_40km.to_netcdf('/scratch2/shreyas/GrIS_paleo_data/fake_surfvel_data_40kms.nc', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86b5175e-2a34-4a1d-bb4e-99d9b8fbfc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_430466/3994453341.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  filtered /= weight\n"
     ]
    }
   ],
   "source": [
    "def gaussian_filter_nan(array, sigma = 5):\n",
    "    \"\"\"Applies Gaussian filter while ignoring NaNs.\"\"\"\n",
    "    nan_mask = np.isnan(array)  # Identify NaNs\n",
    "\n",
    "    # Replace NaNs with 0 temporarily\n",
    "    array_filled = np.where(nan_mask, 0, array)\n",
    "\n",
    "    # Apply Gaussian filter to the data\n",
    "    filtered = gaussian_filter(array_filled, sigma=sigma, mode=\"nearest\")\n",
    "\n",
    "    # Create a weight mask (1 where valid data, 0 where NaNs)\n",
    "    weight_mask = np.where(nan_mask, 0, 1).astype(float)  # Converts True/False → 1.0/0.0\n",
    "    weight = gaussian_filter(weight_mask, sigma=sigma, mode=\"nearest\")\n",
    "\n",
    "    # Normalize the filtered data\n",
    "    filtered /= weight\n",
    "    filtered[nan_mask] = np.nan  # Restore NaNs\n",
    "\n",
    "    return filtered\n",
    "\n",
    "vs_data[vs_data > 1.e9] = np.nan\n",
    "vs_data = gaussian_filter_nan(vs_data)\n",
    "da_vs_data = xr.DataArray(\n",
    "        data = vs_data,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = ys,\n",
    "            x = xs,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vs in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "vx_data[vx_data < -1.e9] = np.nan\n",
    "vx_data = gaussian_filter_nan(vx_data)\n",
    "da_vx_data = xr.DataArray(\n",
    "        data = vx_data,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = ys,\n",
    "            x = xs,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vx in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "vy_data[vy_data < -1.e9] = np.nan\n",
    "vy_data = gaussian_filter_nan(vy_data)\n",
    "da_vy_data = xr.DataArray(\n",
    "        data = vy_data,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = ys,\n",
    "            x = xs,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vy in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "vx_uncert_data[vx_uncert_data < -1.e9] = np.nan\n",
    "vx_uncert_data = gaussian_filter_nan(vx_uncert_data)\n",
    "da_vx_uncert_data = xr.DataArray(\n",
    "        data = vx_uncert_data,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = ys,\n",
    "            x = xs,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vx_uncert in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "\n",
    "vy_uncert_data[vy_uncert_data < -1.e9] = np.nan\n",
    "vy_uncert_data = gaussian_filter_nan(vy_uncert_data)\n",
    "da_vy_uncert_data = xr.DataArray(\n",
    "        data = vy_uncert_data,\n",
    "        dims = [\"y\", \"x\"],\n",
    "        coords = dict(\n",
    "            y = ys,\n",
    "            x = xs,\n",
    "        ),  \n",
    "        attrs = dict(description=\"vy_uncert in ma^(-1)\"),\n",
    "    )\n",
    "\n",
    "\n",
    "da_vs_data_interp = da_vs_data.interp(x = xModel40, \n",
    "                                      y = yModel40,\n",
    "                                      method = \"linear\")\n",
    "da_vx_data_interp = da_vx_data.interp(x = xModel40, \n",
    "                                      y = yModel40,\n",
    "                                      method = \"linear\")\n",
    "da_vy_data_interp = da_vy_data.interp(x = xModel40, \n",
    "                                      y = yModel40,\n",
    "                                      method = \"linear\")\n",
    "da_vx_uncert_data_interp = da_vx_uncert_data.interp(x = xModel40, \n",
    "                                                    y = yModel40,\n",
    "                                                    method = \"linear\")\n",
    "da_vy_uncert_data_interp = da_vy_uncert_data.interp(x = xModel40, \n",
    "                                                    y = yModel40,\n",
    "                                                    method = \"linear\")\n",
    "\n",
    "da_vs_data_interp_manual = da_vs_data_interp.copy()\n",
    "da_vx_data_interp_manual = da_vx_data_interp.copy()\n",
    "da_vy_data_interp_manual = da_vy_data_interp.copy()\n",
    "da_vx_uncert_data_interp_manual = da_vx_uncert_data_interp.copy()\n",
    "da_vy_uncert_data_interp_manual = da_vy_uncert_data_interp.copy()\n",
    "\n",
    "da_vs_data_interp = da_vs_data_interp.fillna(-1.e9)\n",
    "da_vx_data_interp = da_vx_data_interp.fillna(-1.e9)\n",
    "da_vy_data_interp = da_vy_data_interp.fillna(-1.e9)\n",
    "da_vx_uncert_data_interp = da_vx_uncert_data_interp.fillna(-1.e9)\n",
    "da_vy_uncert_data_interp = da_vy_uncert_data_interp.fillna(-1.e9)\n",
    "\n",
    "for j in range(len(yModel40)):\n",
    "    for i in range(len(xModel40)):\n",
    "\n",
    "        j_data, alpha_y = ageData.find_alpha(ys, yModel40[j])\n",
    "        i_data, alpha_x = ageData.find_alpha(xs, xModel40[i])\n",
    "\n",
    "        if alpha_x is not None and alpha_y is not None:\n",
    "            \n",
    "            da_vs_data_interp_manual[j, i] = alpha_y*alpha_x*vs_data[j_data+1, i_data+1]\\\n",
    "                                            + (1-alpha_y)*alpha_x*vs_data[j_data, i_data+1]\\\n",
    "                                            + alpha_y*(1-alpha_x)*vs_data[j_data+1, i_data]\\\n",
    "                                            + (1-alpha_y)*(1-alpha_x)*vs_data[j_data, i_data]\n",
    "            da_vx_data_interp_manual[j, i] = alpha_y*alpha_x*vx_data[j_data+1, i_data+1]\\\n",
    "                                            + (1-alpha_y)*alpha_x*vx_data[j_data, i_data+1]\\\n",
    "                                            + alpha_y*(1-alpha_x)*vx_data[j_data+1, i_data]\\\n",
    "                                            + (1-alpha_y)*(1-alpha_x)*vx_data[j_data, i_data]\n",
    "            da_vy_data_interp_manual[j, i] = alpha_y*alpha_x*vy_data[j_data+1, i_data+1]\\\n",
    "                                            + (1-alpha_y)*alpha_x*vy_data[j_data, i_data+1]\\\n",
    "                                            + alpha_y*(1-alpha_x)*vy_data[j_data+1, i_data]\\\n",
    "                                            + (1-alpha_y)*(1-alpha_x)*vy_data[j_data, i_data]\n",
    "\n",
    "            da_vx_uncert_data_interp_manual[j, i] = np.sqrt(alpha_y**2*alpha_x**2*vx_uncert_data[j_data+1, i_data+1]**2\\\n",
    "                                                  + (1-alpha_y)**2*alpha_x**2*vx_uncert_data[j_data, i_data+1]**2\\\n",
    "                                                  + alpha_y**2*(1-alpha_x)**2*vx_uncert_data[j_data+1, i_data]**2\\\n",
    "                                                  + (1-alpha_y)**2*(1-alpha_x)**2*vx_uncert_data[j_data, i_data]**2)\n",
    "            da_vy_uncert_data_interp_manual[j, i] = np.sqrt(alpha_y**2*alpha_x**2*vy_uncert_data[j_data+1, i_data+1]**2\\\n",
    "                                                  + (1-alpha_y)**2*alpha_x**2*vy_uncert_data[j_data, i_data+1]**2\\\n",
    "                                                  + alpha_y**2*(1-alpha_x)**2*vy_uncert_data[j_data+1, i_data]**2\\\n",
    "                                                  + (1-alpha_y)**2*(1-alpha_x)**2*vy_uncert_data[j_data, i_data]**2)\n",
    "\n",
    "da_vs_data_interp_manual = da_vs_data_interp_manual.fillna(-1.e9)\n",
    "da_vx_data_interp_manual = da_vx_data_interp_manual.fillna(-1.e9)\n",
    "da_vy_data_interp_manual = da_vy_data_interp_manual.fillna(-1.e9)\n",
    "da_vx_uncert_data_interp_manual = da_vx_uncert_data_interp_manual.fillna(-1.e9)\n",
    "da_vy_uncert_data_interp_manual = da_vy_uncert_data_interp_manual.fillna(-1.e9)\n",
    "\n",
    "modelPath = '/home/shreyas/update_to_develop_sicopolis/sicopolis_spinups/sico_out/'\n",
    "dataPath = '/scratch2/shreyas/GrIS_paleo_data/'\n",
    "\n",
    "ds_surfvel_data_40km_gs_before = xr.open_dataset(dataPath + 'surfvel_data_40kms.nc')\n",
    "ds_surfvel_data_40km_orig = xr.open_dataset(dataPath + 'surfvel_data_40kms_orig.nc')\n",
    "\n",
    "ds_surfvel_data_40km_gs_before[\"vs_orig\"] = ds_surfvel_data_40km_orig[\"vs\"].copy()\n",
    "ds_surfvel_data_40km_gs_before[\"vs\"] = da_vs_data_interp\n",
    "ds_surfvel_data_40km_gs_before[\"vx\"] = da_vx_data_interp\n",
    "ds_surfvel_data_40km_gs_before[\"vy\"] = da_vy_data_interp\n",
    "ds_surfvel_data_40km_gs_before[\"vx_uncert\"] = da_vx_uncert_data_interp\n",
    "ds_surfvel_data_40km_gs_before[\"vy_uncert\"] = da_vy_uncert_data_interp\n",
    "ds_surfvel_data_40km_gs_before[\"vs_manual\"] = da_vs_data_interp_manual\n",
    "ds_surfvel_data_40km_gs_before[\"vx_manual\"] = da_vx_data_interp_manual\n",
    "ds_surfvel_data_40km_gs_before[\"vy_manual\"] = da_vy_data_interp_manual\n",
    "ds_surfvel_data_40km_gs_before[\"vx_uncert_manual\"] = da_vx_uncert_data_interp_manual\n",
    "ds_surfvel_data_40km_gs_before[\"vy_uncert_manual\"] = da_vy_uncert_data_interp_manual\n",
    "!rm /scratch2/shreyas/GrIS_paleo_data/surfvel_data_40kms_gs_before.nc\n",
    "ds_surfvel_data_40km_gs_before.to_netcdf(dataPath + 'surfvel_data_40kms_gs_before.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_LRP",
   "language": "python",
   "name": "py310_lrp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
